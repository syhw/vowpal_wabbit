Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.626139   0.626139            1         1.0   1.0000   0.2087       51
0.593351   0.560564            2         2.0   0.0000   0.7487      104
0.402801   0.212251            4         4.0   0.0000   0.4117      135
0.307449   0.212097            8         8.0   0.0000   0.3386      146
0.277068   0.246686           16        16.0   1.0000   0.3321       24
0.260138   0.243209           32        32.0   0.0000   0.3743       32
0.250310   0.240481           64        64.0   0.0000   0.3416       61
0.248524   0.246738          128       128.0   1.0000   0.5215      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200
weighted label sum = 91
average loss = 0.240319
best constant = 0.455
best constant's loss = 0.247975
total feature number = 15482
